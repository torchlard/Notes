# skills
Experienced in deploying data solutions and cloud infrastructure via CI/CD pipelines
Experienced in deploying Infrastructure as Code (Terraform / Cloudformation etc)
Knowledge of REST/Graph APIs and how they can be used in a data environment.
Knowledge of Docker/Kubernetes, and how these can be used to simplify deployments.
Solid Python data and development experience with major SDKâ€™s / packages

Experienced in deploying Infrastructure as Code (Terraform / Cloudformation etc)



Deep technical knowledge of complex (and simple) data architectures, covering all aspects (compliance, risk, security) of our requirements
Detailed knowledge of the concepts and principles of data engineering

Sound awareness of Data Management best practice, including data lifecycle management

Extensive skills in SQL, both at production grade and at analytical level, gained through intensive application in a commercial business environment

Experience of building large scale data pipelines on at least one Cloud Platform (GCP and AWS preferred)

Can deliver complex big data solutions with structured and unstructured data

Excellent oral and written communication skills for all levels of an organisation

Collaborate to identify how work activities across the teams are related and highlight inefficiencies. You help to remove barriers and find the resources or support needed to improve processes

Some knowledge of Cloud Computing patterns, workflows and services; and how they relate to a big data platform.

Advanced math skills (linear algebra, Baysesian statistics, group theory)
Background in machine learning & software engineering frameworks such as TensorFlow or Keras









