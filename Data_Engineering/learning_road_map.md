1. coding basis
SQL, Python, Linux

2. build your first project
build basic flask API

3. learn data warehouse
- read Kimball's data warehouse guide
- Basics to Data Warehousing Udemy
- An indroduction in Data Engineering

4. build your second project
- scrape an online source
- store encrypted data into SFTP
- create dimensional model
- pull data from SFTP and load into data warehouse

5. learn workflow tools
launch airflow with docker

6. learn about testing
check out TDD course like Unit TDD for python

7. learn cloud and NoSQL
cloud data warehouse and ETLs using Google Data Cert / Azure

FreeCodeCamps - Database Systems
Cornell University Course (SQL, NoSQL, Large Scale Data Analysis)

8. learn streaming and distributed system
Andrea's video how to install Apache Kafka
Frank Kane's Course on Spark and Hadoop
StartDataEngineerings Project

9. start studying for interviews
DS, algorithm, SQL

10. build your third project
use cloud managed services to stream data, 
pair with batch ETL tool that pull from a second source

11. learn enough UI/UX and dashboarding


12. pick some of your own
found some personal favorites in terms of tool types






